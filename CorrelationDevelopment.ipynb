{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "from pymks.stats import correlate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "    >>> from pymks import PrimitiveBasis\n",
    "    >>> prim_basis = PrimitiveBasis(2, [0, 1])\n",
    "    >>>\n",
    "    >>> np.random.seed(0)\n",
    "    >>> X = np.random.randint(2, size=(1, 3))\n",
    "    >>> X_corr = correlate(X, prim_basis)\n",
    "    >>> X_result = np.array([[0, 0.5, 0],\n",
    "    ...                      [1 / 3., 2 / 3., 0],\n",
    "    ...                      [0, 0.5, 0.5]])\n",
    "    >>> assert np.allclose(X_corr, X_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _auto_correlations(n_states):\n",
    "    \"\"\"Returns list of autocorrelations\n",
    "\n",
    "    Args:\n",
    "        n_states: number of local states\n",
    "\n",
    "    Returns:\n",
    "        list of tuples for autocorrelations\n",
    "\n",
    "    >>> l = _auto_correlations(np.arange(3))\n",
    "    >>> assert l == ((0, 1, 2), (0, 1, 2))\n",
    "    \"\"\"\n",
    "    n_states=np.arange(n_states)\n",
    "    return tuple(n_states), tuple(n_states)\n",
    "\n",
    "\n",
    "def _cross_correlations(n_states):\n",
    "    \"\"\"Returns list of crosscorrelations\n",
    "\n",
    "    Args:\n",
    "        n_states: number of local states\n",
    "\n",
    "    Returns:\n",
    "        list of tuples for crosscorrelations\n",
    "\n",
    "    >>> l = _cross_correlations(np.arange(3))\n",
    "    >>> assert l == ((0, 0, 1), (1, 2, 2))\n",
    "    \"\"\"\n",
    "    n_states=np.arange(n_states)\n",
    "    l = range(len(n_states))\n",
    "    cross_corr = [[(l[i], l[j]) for j in l[1:][i:]] for i in l[:-1]]\n",
    "    flat_corr = [item for sublist in cross_corr for item in sublist]\n",
    "    l_0 = tuple([_l[0] for _l in flat_corr])\n",
    "    l_1 = tuple([_l[1] for _l in flat_corr])\n",
    "    return l_0, l_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Get the number of states\n",
    "L=3\n",
    "_auto, _cross = _auto_correlations(L), _cross_correlations(L)\n",
    "correlations = (_auto[0] + _cross[0], _auto[1] + _cross[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 1, 2, 0, 0, 1), (0, 1, 2, 1, 2, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2=_cross_correlations(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 0, 1), (1, 2, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _correlations_to_indices(correlations, n_states):\n",
    "    \"\"\"\n",
    "    Helper function to select correct indices given the local state values in\n",
    "    basis.n_states.\n",
    "\n",
    "    Args:\n",
    "        correlations: list of correlations to be computed\n",
    "        basis: an instance of a basis class.\n",
    "\n",
    "    Returns:\n",
    "        list of correlations in terms of indices\n",
    "    \"\"\"   \n",
    "    n_states=np.arange(n_states)\n",
    "    try:\n",
    "        l_0 = tuple([list(n_states).index(_l[0]) for _l in correlations])\n",
    "        l_1 = tuple([list(n_states).index(_l[1]) for _l in correlations])\n",
    "    except ValueError as ve:\n",
    "        raise ValueError('correlations value ' + str(ve) +\n",
    "                         ' is not in basis.n_states')\n",
    "    return (l_0, l_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correlations=[(0,0),(0,1),(1,1)]\n",
    "\n",
    "\n",
    "a=_correlations_to_indices(correlations,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 0, 1), (0, 1, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations2=[(0, 0), (1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(correlations2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(correlations2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'correlations1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2e883301d3f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mtest_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-2e883301d3f3>\u001b[0m in \u001b[0;36mtest_classification\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;34m\"Correlations\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 TwoPointcorrelation(\n\u001b[0;32m---> 24\u001b[0;31m                     \u001b[0mperiodic_boundary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcutoff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrelations1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrelations2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 ),\n\u001b[1;32m     26\u001b[0m             ),\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'correlations1'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dask.array as da\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pymks.fmks.correlations import FlattenTransformer, TwoPointcorrelation\n",
    "from pymks.fmks.data.cahn_hilliard import generate\n",
    "from pymks.fmks.bases.legendre import LegendreTransformer\n",
    "\n",
    "\n",
    "def test_classification():\n",
    "    \"\"\"This test basically creates Legendre microstructures in both times:\n",
    "    0 and t.  Then builds homogenization classification linkages to\n",
    "    classify if newly generated microstructures are at time 0 or t\n",
    "    \"\"\"\n",
    "    reducer = PCA(n_components=3)\n",
    "    linker = LogisticRegression()\n",
    "    homogenization_pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"discretize\", LegendreTransformer(n_state=3, min_=-1.0, max_=1.0)),\n",
    "            (\n",
    "                \"Correlations\",\n",
    "                TwoPointcorrelation(\n",
    "                    periodic_boundary=True, cutoff=10, correlations1=1, correlations2=1\n",
    "                ),\n",
    "            ),\n",
    "            (\"flatten\", FlattenTransformer()),\n",
    "            (\"reducer\", reducer),\n",
    "            (\"connector\", linker),\n",
    "        ]\n",
    "    )\n",
    "    da.random.seed(3)\n",
    "    x0_phase, x1_phase = generate(shape=(50, 21, 21))\n",
    "    y0_class = np.zeros(x0_phase.shape[0])\n",
    "    y1_class = np.ones(x1_phase.shape[0])\n",
    "    x_combined = np.concatenate((x0_phase, x1_phase))\n",
    "    y_combined = np.concatenate((y0_class, y1_class))\n",
    "    homogenization_pipeline.fit(x_combined, y_combined)\n",
    "    x0_test, x1_test = generate(shape=(3, 21, 21))\n",
    "    y1_test = homogenization_pipeline.predict(x1_test)\n",
    "    y0_test = homogenization_pipeline.predict(x0_test)\n",
    "    assert np.allclose(y0_test, [0, 0, 0])\n",
    "    assert np.allclose(y1_test, [1, 1, 1])\n",
    "\n",
    "\n",
    "test_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Berkay Use correlations to indices\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pymks.fmks.correlations import FlattenTransformer, TwoPointcorrelation\n",
    "from pymks.fmks.data.cahn_hilliard import generate\n",
    "from pymks.fmks.bases.legendre import LegendreTransformer\n",
    "x0_phase, x1_phase = generate(shape=(50, 21, 21))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=LegendreTransformer(n_state=3, min_=-1.0, max_=1.0).transform(x0_phase).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 21, 21, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymks.fmks.correlations import two_point_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=TwoPointcorrelation(periodic_boundary=True, cutoff=None, correlations=[(0,0),(1,1)]).transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 15, 15, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz import pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((2,2,2)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correl=np.ndarray([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correl[0,:,:,:]=np.zeros((2,2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations=[(0,0),(0,1)]\n",
    "len(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Cor in correlations:\n",
    "    print(Cor[0],Cor[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Cor in correlations:\n",
    "    correl=[]\n",
    "    br=pipe(\n",
    "        a,\n",
    "        lambda x: da.from_array(x, chunks=x.shape),\n",
    "        lambda x: (x[..., Cor[0]], x[..., Cor[1]]),\n",
    "        lambda x: two_point_stats(\n",
    "            *x, periodic_boundary=True, cutoff=8\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "br.compute().shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.empty((10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=TwoPointcorrelation(periodic_boundary=True, cutoff=None, correlations=[(1,1)]).transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations1=0\n",
    "correlations2=0\n",
    "correlations=[(0,0),(1,1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymks.fmks.func import rcompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_assign(cor):\n",
    "    corr1=cor[0]\n",
    "    corr2=cor[1]\n",
    "    return corr1,corr2\n",
    "    \n",
    "cor_assign(correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz.curried import curry\n",
    "from toolz.curried import map as map_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy=[(1,1),(2,1)]\n",
    "\n",
    "@curry\n",
    "def add(i, x):\n",
    "    return i + x[0] + x[1]\n",
    "\n",
    "def calc(i, values):\n",
    "    return map(add(i), values)\n",
    "#rcompose(lambda x: 2*x,map(lambda x:x+yy[0]+yy[1])\n",
    " \n",
    "print(list(calc(3, yy)))\n",
    "         \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy=[(1,1),(2,1)]\n",
    "\n",
    "@curry\n",
    "def add(i, x):\n",
    "    return i + x[0] + x[1]\n",
    "\n",
    "def calc(i, values):\n",
    "    return pipe(\n",
    "        values,\n",
    "        map_(add(i))\n",
    "    )\n",
    "#rcompose(lambda x: 2*x,map(lambda x:x+yy[0]+yy[1])\n",
    " \n",
    "print(list(calc(3, yy)))\n",
    "         \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "aa = list(map_(lambda _: np.random.random(150).reshape((5, 6, -1)), range(4)))\n",
    "np.stack(aa, axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rcompose(lambda x: da.from_array(x, chunks=x.shape),\n",
    "            map(lambda x,correlations: (x[..., correlations[0]], x[..., correlations[1]]),correlations),\n",
    "            lambda x: two_point_stats(\n",
    "                *x, periodic_boundary=True, cutoff=None\n",
    "            ),)(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=pipe(\n",
    "            a,\n",
    "            lambda x: da.from_array(x, chunks=x.shape),\n",
    "            lambda x: (x[..., correlations[0]], x[..., correlations[1]]),\n",
    "            lambda x: two_point_stats(\n",
    "                *x, periodic_boundary=True, cutoff=None\n",
    "            ),\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

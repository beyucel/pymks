{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the large casestudy for the damage dataset. Data that we are reading is 34Gb and device that I have is 32 GB so technically I cannot play around with this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress,wait\n",
    "import tables\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/berkay/Projects/pymks/data/ms_copy_data.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tps_hdf5_file = tables.open_file(path, mode='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_2ps(phase):\n",
    "    global ndim\n",
    "    from pymks.stats import correlate\n",
    "    from pymks import PrimitiveBasis\n",
    "    import numpy as np\n",
    "    prim_basis=PrimitiveBasis(n_states=2)\n",
    "    interface=phase[ndim**3:]\n",
    "    phase=phase[:ndim**3]\n",
    "    phase_mks=phase.reshape((1,ndim,ndim,ndim))\n",
    "    interface_mks=interface.reshape((1,ndim-1,ndim-1,ndim-1))\n",
    "    phase_auto=correlate(phase_mks,prim_basis,periodic_axes=(0,1,2))\n",
    "    auto_11=phase_auto[0,:,:,:,0]\n",
    "    intcorr=correlate(interface_mks,prim_basis,periodic_axes=(0,1,2))\n",
    "    autoint=intcorr[0,:,:,:,0]\n",
    "    autoint=1-autoint\n",
    "    tot_2ps=np.column_stack([np.reshape(auto_11,(1,ndim**3)),\\\n",
    "                             np.reshape(autoint,(1,(ndim-1)**3))])\n",
    "    return tot_2ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsample=1000\n",
    "ndim=51\n",
    "chunksize=1300\n",
    "ndim_data=da.from_array(np.repeat(ndim,nsample).T,chunks=(chunksize,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_data=tps_hdf5_file.root.ms_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit MicrostructureData=Full_Data[:,0:51**3+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=da.from_array(Full_Data,chunks=(1300,257651))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nix/store/02z0vx25y0x2arfvcp89pvy52a3q77wf-python3.7-distributed-2.9.1/lib/python3.7/site-packages/distributed/dashboard/core.py:72: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.27861833 0.2781434  0.27723123 ... 0.580456   0.580808   0.580992  ]\n",
      " [0.27745739 0.27855048 0.27940988 ... 0.577224   0.577376   0.5778    ]\n",
      " [0.27674876 0.27571598 0.27582906 ... 0.579144   0.580592   0.5798    ]\n",
      " ...\n",
      " [0.26429503 0.26529012 0.26804924 ... 0.584312   0.584152   0.584888  ]\n",
      " [0.27831679 0.2790028  0.27947019 ... 0.57748    0.576512   0.575848  ]\n",
      " [0.27186376 0.27049928 0.26819247 ... 0.586736   0.587096   0.5884    ]]\n",
      "1 Chunks completed\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    client=Client()\n",
    "    ms_chunk=np.array([ms_data[i*chunksize:(i+1)*chunksize]])\n",
    "    ms_chunk=ms_chunk.reshape((chunksize,ms_data.shape[1]))\n",
    "    # ms_chunk=da.from_array(ms_chunk)\n",
    "    futures=client.map(calc_2ps,ms_chunk)\n",
    "    wait(futures)\n",
    "    tot_2ps=client.gather(futures)\n",
    "    tot_2ps=np.stack(tot_2ps)\n",
    "    tot_2ps=tot_2ps.reshape((chunksize,ms_data.shape[1]))\n",
    "    client.close()\n",
    "#         tps_data_storage.append(tot_2ps)\n",
    "#         tps_data_storage.flush()\n",
    "    # tot_2ps=da.map_blocks(calc_2ps,ms_chunk).compute()\n",
    "    if(i==0):\n",
    "        print(tot_2ps)\n",
    "    # tps_data[i*chunksize:(i+1)*chunksize,ms_data.shape[1],:]=da.asarray(tot_2ps.reshape((chunksize,ms_data.shape[1])))\n",
    "    # tps_data[i*chunksize:(i+1)*chunksize,ms_data.shape[1],:]=da.from_array(tot_2ps.reshape((chunksize,ms_data.shape[1])))\n",
    "    print(\"%d Chunks completed\"%(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1300, 257651)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_2ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pymks.fmks.bases.primitive import PrimitiveTransformer\n",
    "# from pymks.fmks.correlations import TwoPointCorrelation,FlattenTransformer\n",
    "# # from sklearn.decomposition import PCA\n",
    "# from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bl = Pipeline(steps=[\n",
    "#     (\"discritize\",PrimitiveTransformer(n_state=2, min_=0.0, max_=1.0)),\n",
    "#     (\"Correlations\",TwoPointCorrelation(periodic_boundary=True, cutoff=25,correlations=[(1,1),(0,1)])),\n",
    "#     ('flatten', FlattenTransformer()),  \n",
    "#     ('reducer',PCA())])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
